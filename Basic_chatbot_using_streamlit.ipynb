{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x8xhXb7ndVyx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "839ce022-88bf-4f94-f28c-f07f170c2ffb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.4/8.4 MB\u001b[0m \u001b[31m15.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.4/196.4 kB\u001b[0m \u001b[31m21.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.8/4.8 MB\u001b[0m \u001b[31m35.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m82.1/82.1 kB\u001b[0m \u001b[31m10.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pyngrok\n",
            "  Downloading pyngrok-7.0.5-py3-none-any.whl (21 kB)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from pyngrok) (6.0.1)\n",
            "Installing collected packages: pyngrok\n",
            "Successfully installed pyngrok-7.0.5\n"
          ]
        }
      ],
      "source": [
        "!pip install -q streamlit\n",
        "!pip install pyngrok"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ngrok authtoken 2XJcMWVd8A5gZbLT1Mbd8f5q8id_2QJzWvWHVpCEWDDA8XUmD"
      ],
      "metadata": {
        "id": "xk3cCiqldqWK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fed7bc1c-54a5-4d97-81d0-df1e9dec1607"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Authtoken saved to configuration file: /root/.config/ngrok/ngrok.yml\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ngrok"
      ],
      "metadata": {
        "id": "ZK7H-129dxyg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile app.py\n",
        "import streamlit as st\n",
        "import nltk\n",
        "import string\n",
        "import random\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "nltk.download('punkt')\n",
        "nltk.download('wordnet')\n",
        "\n",
        "lemmer = nltk.stem.WordNetLemmatizer()\n",
        "\n",
        "GREET_INPUTS = ['hello', 'hi', 'hey']\n",
        "GREET_RESPONSES = ['hi', 'hey', \"what's up\", 'I am glad! You are talking to me']\n",
        "\n",
        "remove_punct_dict = dict((ord(punct), None) for punct in string.punctuation)\n",
        "\n",
        "\n",
        "def convert_to_lower(text):\n",
        "    return text.lower()\n",
        "\n",
        "def LemTokens(tokens):\n",
        "    return [lemmer.lemmatize(token) for token in tokens]\n",
        "\n",
        "\n",
        "def LemNormalize(text):\n",
        "    return LemTokens(nltk.word_tokenize(text.lower().translate(remove_punct_dict)))\n",
        "\n",
        "def greet(sentence):\n",
        "    for word in sentence.split():\n",
        "        if word.lower() in GREET_INPUTS:\n",
        "            return random.choice(GREET_RESPONSES)\n",
        "\n",
        "def bot_response(user_response, sent_tokens):\n",
        "    robo1_response = ''\n",
        "    TfidVec = TfidfVectorizer(tokenizer=LemNormalize, stop_words='english')\n",
        "    tfidf = TfidVec.fit_transform(sent_tokens)\n",
        "    vals = cosine_similarity(tfidf[-1], tfidf)\n",
        "    print(vals.shape)\n",
        "    idx = vals.argsort()[0][-2]\n",
        "    print(idx)\n",
        "    flat = vals.flatten()\n",
        "    flat.sort()\n",
        "    print(flat.shape)\n",
        "    req_tfidf = flat[-2]\n",
        "    print(req_tfidf)\n",
        "\n",
        "    if(req_tfidf==0):\n",
        "        robo1_response = robo1_response + \"I am sorry! I don't understand you\"\n",
        "        return robo1_response\n",
        "\n",
        "    else:\n",
        "        robo1_response = robo1_response + sent_tokens[idx]\n",
        "        return robo1_response\n",
        "\n",
        "def main():\n",
        "\n",
        "#Creating chat interface\n",
        "    favicon_url = 'https://th.bing.com/th/id/OIP.4RnNLKNxFID9JiAfMeWf8gHaHa?rs=1&pid=ImgDetMain'\n",
        "    st.set_page_config(page_title='Basic ChatBot', page_icon=favicon_url)\n",
        "\n",
        "    st.header('Your Friendly Chatbot')\n",
        "    st.write('I am a conversational bot, ready to answer your query! To end the chat type \"exit\".')\n",
        "\n",
        "\n",
        "    with st.sidebar:\n",
        "        st.subheader('Your Documents')\n",
        "        uploaded_file = st.file_uploader('Upload your files here and press \"Process\"', type=\"txt\")\n",
        "\n",
        "\n",
        "    if uploaded_file is not None:\n",
        "        file_contents = uploaded_file.getvalue().decode(\"utf-8\")\n",
        "        raw_doc = convert_to_lower(file_contents)\n",
        "        sent_tokens = nltk.sent_tokenize(raw_doc)\n",
        "        word_tokens = nltk.word_tokenize(raw_doc)\n",
        "\n",
        "#Initializing session state\n",
        "    if 'message' not in st.session_state:\n",
        "        st.session_state.message = []\n",
        "\n",
        "\n",
        "    for message in st.session_state.message:\n",
        "        with st.chat_message(message['role']):\n",
        "            st.markdown(message['content'])\n",
        "\n",
        "#USER RESPONSE\n",
        "    user_question = st.chat_input('Enter your query here')\n",
        "\n",
        "    if user_question:\n",
        "        with st.chat_message('user'):\n",
        "            st.markdown(user_question)\n",
        "        st.session_state.message.append({'role': \"user\", \"content\": user_question})\n",
        "\n",
        "\n",
        "#BOT RESPONSE\n",
        "    if user_question:\n",
        "\n",
        "        response = ''\n",
        "        if(user_question!='exit'):\n",
        "            if(user_question == 'thanks' or user_question == 'thank you'):\n",
        "                with st.chat_message('assistant'):\n",
        "                    response = response + \"You are Welcome\"\n",
        "                    st.markdown(response)\n",
        "                st.session_state.message.append({\"role\": \"assistant\", \"content\": response})\n",
        "\n",
        "            else:\n",
        "                if(greet(user_question)!=None):\n",
        "                    with st.chat_message('assistant'):\n",
        "                        response = response + greet(user_question)\n",
        "                        st.markdown(response)\n",
        "                    st.session_state.message.append({\"role\": \"assistant\", \"content\": response})\n",
        "\n",
        "                else:\n",
        "                    sent_tokens.append(user_question)\n",
        "                    word_tokens = word_tokens + nltk.word_tokenize(user_question)\n",
        "                    final_words = list(set(word_tokens))\n",
        "                    with st.chat_message('assistant'):\n",
        "                        response = response + bot_response(user_question, sent_tokens)\n",
        "                        st.markdown(response)\n",
        "                    sent_tokens.remove(user_question)\n",
        "                    st.session_state.message.append({\"role\": \"assistant\", \"content\": response})\n",
        "\n",
        "\n",
        "        else:\n",
        "            with st.chat_message('assistant'):\n",
        "                response = response + 'GoodBye!'\n",
        "                st.markdown(response)\n",
        "            st.session_state.message.append({\"role\": \"assistant\", \"content\": response})\n",
        "            st.session_state.message = []\n",
        "\n",
        "        #st.session_state.message.append({\"role\": \"assistant\", \"content\": response})\n",
        "        #st.session_state.message = []\n",
        "\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0V1cLzz71ObQ",
        "outputId": "8ef95459-3983-4bbe-ddf6-277ecb638f95"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting app.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!streamlit run app.py &>/dev/null&"
      ],
      "metadata": {
        "id": "CGXP1d2deWWB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pgrep streamlit"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sEL-6KmTebC2",
        "outputId": "301897c8-a931-4164-f526-329ac40bb031"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "829\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyngrok import ngrok\n",
        "# Setup a tunnel to the streamlit port 8501\n",
        "public_url = ngrok.connect(8501)\n",
        "public_url"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x0FDi4qdedGi",
        "outputId": "94371349-4a42-43a0-ea3a-e704ac8b3036"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<NgrokTunnel: \"https://0145-34-80-52-248.ngrok-free.app\" -> \"http://localhost:8501\">"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "18LiaaUoefy4"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}